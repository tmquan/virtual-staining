hydra:
  output_subdir: null
  run:
    dir: .

defaults:
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

data:
  root_folder: "data/ACT2_co-register/"
  train_folders:
  - Subject2_Slide2
  - Subject4_Slide4AIN1
  val_folders:
  - Subject1_Slide1
  test_folders:
  - Subject1_Slide1
  train_samples: 8000
  val_samples: 800
  test_samples: null
  img_shape: 256
  vol_shape: 256
  batch_size: 4

model:
  phase: "unet"
  timesteps: 1000
  prediction_type: "sample" # "sample" or "epsilon" or "v_prediction"
  img_shape: ${data.img_shape}
  vol_shape: ${data.vol_shape}
  batch_size: ${data.batch_size}

train:
  ckpt: ${resume_from_checkpoint}
  strict: 1 if ${resume_from_checkpoint} is not None else 0
  lr: 1e-4
  alpha: 10
  gamma: 1
  delta: 0.01
  perceptual: false
  lamda: 2e-3
  batch_size: ${data.batch_size}
  epochs: 400
  ema_decay: 0.9999 # `-1` disables it


resume_from_checkpoint: null #TODO
test: null


trainer:
  accelerator: auto
  devices: -1
  precision: 32
  strategy: 'ddp_find_unused_parameters_true'
  max_epochs: ${train.epochs}
  enable_model_summary: true
  # amp_backend: apex

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: "validation_loss_epoch"
    mode: "min"
    auto_insert_metric_name: true
    save_top_k: 4
    save_last: true
    filename: "{epoch}-{validation_loss_epoch:.2f}"
    # every_n_epochs: 20
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: 'epoch'
    log_momentum: true
    log_weight_decay: true
  - _target_: lightning.pytorch.callbacks.RichProgressBar
    refresh_rate: 1
  # - _target_: lightning.pytorch.callbacks.StochasticWeightAveraging
  #   swa_lrs: 1e-3  

logger:
  - _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "./logs"
    log_graph: true
    name: ${model.phase}
