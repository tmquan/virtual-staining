hydra:
  output_subdir: null
  run:
    dir: .

defaults:
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

data:
  root_folder: data/ACT2_co-register/
  train_folders:
  - Subject2_Slide2
  - Subject4_Slide4AIN1
  val_folders:
  - Subject1_Slide1
  test_folders:
  # - Subject1_Slide1/Session1
  # - Subject1_Slide1/Session1/Acquisition1_NanoZoomer_20X_noparaffin_aqueouscoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition2_NanoZoomer_20X_noparaffin_nonaqueouscoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition3_NanoZoomer_20X_noparaffin_uncoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition4_NanoZoomer_20X_paraffin_uncoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition5_NanoZoomer_40X_noparaffin_aqueouscoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition6_NanoZoomer_40X_noparaffin_nonaqueouscoverslip_BF
  # - Subject1_Slide1/Session1/Acquisition7_NanoZoomer_40X_noparaffin_uncoverslip_BF
  - Subject1_Slide1/Session1/Acquisition8_MISSING_NanoZoomer_40X_paraffin_uncoverslip_BF
  train_samples: 2000
  val_samples: 400
  test_samples: 1000
  img_shape: 512
  vol_shape: 512
  batch_size: 1

model:
  phase: "unet"
  timesteps: 1000
  prediction_type: "sample" # "sample" or "epsilon" or "v_prediction"
  img_shape: ${data.img_shape}
  vol_shape: ${data.vol_shape}
  batch_size: ${data.batch_size}

train:
  ckpt: ${resume_from_checkpoint}
  strict: 1 if ${resume_from_checkpoint} is not None else 0
  lr: 2e-5
  alpha: 10
  gamma: 1
  delta: 0.1
  perceptual: false
  lamda: 0.1
  batch_size: ${data.batch_size}
  epochs: 400
  ema_decay: 0.9999 # `-1` disables it

resume_from_checkpoint: 'logs/unet/version_0/checkpoints/last.ckpt'
# resume_from_checkpoint: 'logs/unet/version_0/checkpoints/epoch=330-validation_loss_epoch=1.36.ckpt'
test: true

trainer:
  accelerator: auto
  devices: -1
  precision: 32
  strategy: 'ddp_find_unused_parameters_true'
  max_epochs: ${train.epochs}
  enable_model_summary: true
  # amp_backend: apex

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: "validation_loss_epoch"
    mode: "min"
    auto_insert_metric_name: true
    save_top_k: 4
    save_last: true
    filename: "{epoch}-{validation_loss_epoch:.2f}"
    # every_n_epochs: 20
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: 'epoch'
    log_momentum: true
    log_weight_decay: true
  - _target_: lightning.pytorch.callbacks.RichProgressBar
    refresh_rate: 1
  # - _target_: lightning.pytorch.callbacks.StochasticWeightAveraging
  #   swa_lrs: 1e-3  

logger:
  - _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "./logs_test"
    log_graph: true
    name: ${model.phase}
